# NYC-TLC-Data_pipeline
Scalable Docker-based ETL pipeline for analyzing NYC TLC Taxi data using Redis, PostgreSQL, and Tableau â€“ includes real-time processing and insightful traffic analytics.

nyc-tlc-data-pipeline

Scalable Docker-based ETL pipeline for analyzing NYC TLC Taxi data using Redis, PostgreSQL, and Tableau â€“ includes real-time processing and insightful traffic analytics.
ğŸš– NYC TLC Data Engineering Pipeline

ğŸ“˜ Project Title: Customer and Traffic Insights with TLC Data

ğŸ“ Course: Data Engineering
ğŸ“Œ Overview

This project builds aÂ scalable end-to-end ETL pipelineÂ to analyze New York City Taxi (TLC) data. It combinesÂ Dockerized services,Â RedisÂ for caching,Â PostgreSQLÂ for structured storage, andÂ TableauÂ for data visualization, enabling actionable insights into urban mobility, customer behavior, and payment trends.

ğŸ› ï¸ Tools & Technologies

* Docker ğŸ³
* Redis âš¡ (for real-time caching)
* PostgreSQL ğŸ˜ (with PGAdmin)
* Tableau ğŸ“Š (for visualization)
* Python (Producer & Consumer scripts)
* NYC TLC Taxi Data (Yellow Taxi - 2024, 100k+ records)

ğŸ§± Pipeline Architecture

Excel Preprocessing â Redis Producer â Consumer â PostgreSQL â Tableau
Components (Docker Containers):
* Producer
* Consumer
* Redis Server
* PostgreSQL
* PGAdmin

ğŸ§ª Dataset

Source:Â NYC TLC Trip Dataâ€¨Size:Â 15 MB (100,000 records)â€¨Fields (19 total):
* Pickup & Drop-off Timestamps
* Trip Distance, Fare, Taxes, Tip
* Payment Type, Passenger Count
* Latitude/Longitude for pickups & drop-offs

âš™ï¸ Setup Instructions

1. Clone the repository
2. Modify yourÂ .envÂ orÂ .ymlÂ file for ports and credentials
3. Run:docker compose build
4. docker compose up
